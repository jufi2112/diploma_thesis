method:
    name: "gaussian_process" # used as directory name --> no invalid characters
    mode: "sequential" # search_only, evaluate_only, sequential

    extended_learning_rates: true # false --> only search for model weight learning rates; true --> also search for alpha and beta learning rates

    # interval from where the learning rates should be sampled (both boundaries included)
    # if you want to exclude a boundary, provide an epsilon in interval_epsilon
    learning_rate_interval: {'w_search': [0, 1], 'w_eval': [0, 1], 'alpha': [0, 1], 'beta': [0, 1]}

    # By default, torch uniform samples the both interval boundaries inclusively. If you don't want this, you can provide an epsilon which is added / subtracted from the boundary
    interval_epsilon: {'w_search': [1e-6, 1e-6], 'w_eval': [1e-6, 1e-6], 'alpha': [1e-6, 1e-6], 'beta': [1e-6, 1e-6]}

    random_samples: 4

    # if you want to manually provide starting points for the GP, add them like follows:
    # [[lr_search_1, lr_eval_1], [lr_search_2, lr_eval_2], ...]
    # if you already have corresponding validation values, provide them in manual_random_samples_results
    manual_random_samples: null

    # results of the manual samples provided above. If you have no results, keep null
    manual_random_samples_results: null

    gp_seed: 0

    # whether the validation errors that are used as target sould be standardized
    # also changes num_restarts and raw_samples during acquisition function optimization
    standardize_valid_errors: true

hydra:
    run:
        dir: D:\\Users\\Julien\\Documents\\Diplom_Results\\experiments_da\\${method.name}

train_search_phase:
    init_channels: 40

train_eval_phase:
    init_channels: 36